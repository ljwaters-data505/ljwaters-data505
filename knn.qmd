---
title: $K$NN
author: "Landon Waters"
date: "02/10/2025"

format: 
  html:
    theme: superhero  
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true

---

**Abstract:**

This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/knn.qmd) hosted on GitHub pages.

# 1. Setup

```{r}
library(tidyverse)
library(caret)
library(fastDummies)
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/pinot.rds")))
```

## 2. $K$NN Concepts

> <span style="color:red;font-weight:bold">TODO</span>: *The quality of your prediction in a $K$NN test is affected greatly by the $K$ you choose. If a $K$ value is too low, outside noise will be captured, and the predictive ability of the model will fall as it can't be generalized. However, when too great a value is selected, the data will be overgeneralized and will not have accurate predictions either because they are too broad.*

## 3. Feature Engineering

1. Create a version of the year column that is a *factor* (instead of numeric).
2. Create dummy variables that indicate the presence of "cherry", "chocolate" and "earth" in the description.
  - Take care to handle upper and lower case characters.
3. Create 3 new features that represent the interaction between *time* and the cherry, chocolate and earth indicators.
4. Remove the description column from the data.

```{r}
# ds modification
ds=wine%>%
  mutate(
    description = str_to_lower(description),
    cherry = ifelse(str_detect(description, "cherry"), 1, 0),
    choc = ifelse(str_detect(description, "chocolate"), 1, 0),
    earth = ifelse(str_detect(description, "earth"), 1, 0),
    
    # feature creation
    cherry_yr = year*cherry,
    choc_yr = year*choc,
    earth_yr = year*earth,
    
    year = as.factor(year) # don't want this to be Box-Cox-ified
    )%>%
  select(-description)
```

## 4. Preprocessing

1. Preprocess the dataframe from the previous code block using BoxCox, centering and scaling of the numeric features
2. Create dummy variables for the `year` factor column

```{r}
ds=ds%>% 
  preProcess(method = c("BoxCox","center","scale"))%>% 
  predict(ds)%>%
  dummy_cols(select_columns = "year")
```

## 5. Running $K$NN

1. Split the dataframe into an 80/20 training and test set
2. Use Caret to run a $K$NN model that uses our engineered features to predict province
  - use 5-fold cross validated subsampling 
  - allow Caret to try 15 different values for $K$
3. Display the confusion matrix on the test data

```{r}
set.seed(505)

wine_index=createDataPartition(ds$province,p=0.8,list=F)
train=ds[wine_index,]
test=ds[-wine_index,]

model=train(province ~ .,
            data=train, 
            method="knn",
            tuneLength=15,
            metric="Kappa",
            trControl=trainControl(method = "cv", number = 5)
            )

pred=predict(model,newdata = test)

# confusion matrix requires inputs to be factors
test=test%>%
  mutate(province=as.factor(province))
confusionMatrix(pred,test$province)
```

## 6. Kappa

How do we determine whether a Kappa value represents a good, bad or some other outcome?

> <span style="color:red;font-weight:bold">TODO</span>: *In the words of Calvin, a good rule of thumb is less than 0.2 is not very good, 0.21 - 0.4 is OK, 0.41 - 0.6 is pretty good, 0.6 - 0.8 is great, greater than 0.8 is almost perfect. If Kappa is equal to zero, the prediction essentially happened by chance. Kappa represents the accuracy above what would just be random guessing. We got a value of 0.3558 (just OK).*

## 7. Improvement

How can we interpret the confusion matrix, and how can we improve in our predictions?

> <span style="color:red;font-weight:bold">TODO</span>: *The confusion matrix makes a table where the rows are the model predictions and the columns are the actual (ground truth) values. While the diagonal of the matrix represents accurate predictions, this is not the only thing that matters. The prediction could have been by random chance, so we need to check out the Kappa value, precision (Pos Pred Value), and recall (sensitivity). Using all this information, we can target the weaknesses of the model and reiterate and improve.*
